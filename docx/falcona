



它将视觉空间信息转换为文本序列形式，具体表现如下：
空间信息在文本中的编码方式
XML标记格式：模型使用特殊的XML标记（如<poly>, <box>等）来表示不同类型的空间对象
坐标直接嵌入文本：
坐标值被直接编码到文本序列中，如：
   <poly><465><221><443><279>...</poly>
这里的<465><221>等数字就是实际的坐标值
量化处理：原始图像中的坐标会被量化到1000×1000的网格中，使模型能够以统一的方式处理不同尺寸的图像


空间信息的处理流程
在分割任务中的具体流程：
训练阶段：
原始分割掩码被转换为多边形轮廓
轮廓坐标被量化到1000×1000网格
量化后的坐标被转换为<poly><x1><y1><x2><y2>...</poly>格式
模型学习生成这种格式的坐标序列


推理阶段：
模型生成类似<poly><465><221><443>...</poly>的坐标序列
系统提取这些坐标并将它们重组为(x,y)对
使用dequantize函数将坐标映射回实际图像尺寸
最终通过polygon_to_mask函数生成像素级掩码

本质理解
这种方法的巧妙之处在于：
将空间任务转化为序列生成任务
模型不需要理解"这是坐标"的概念，它只需学习在什么情况下生成什么样的数字序列
通过大量训练样本，模型学会了视觉特征与坐标值之间的映射关系
正是这种设计让Falcon能够用统一的方式（文本生成）处理多种遥感任务，无需为每种任务设计专门的网络结构或损失函数。
不管是分类、检测还是分割，模型都是在预测下一个标记，只是输出的格式不同





















从模仿到理解的过程
Falcon模型对XML格式的"理解"实际上是一种有效的模式识别和映射能力：
初期学习：模型先学习模仿XML标记的使用模式，知道什么时候生成<box>，什么时候生成<poly>
关联学习：模型逐渐关联图像区域与坐标值，学习到视觉空间与数字的映射关系
上下文理解：模型学习不同任务需要的不同格式，根据指令选择合适的输出形式
边界约束：模型学习坐标的有效范围（0-999），以及不同坐标之间的逻辑关系



将XML标记视为普通文本标记：
在训练时，<box>, <quad>, <poly>, <123> 等XML标记被当作普通的文本标记处理
这些标记被分词器(tokenizer)切分为若干词元(tokens)，加入词表
监督式学习：
模型通过监督学习，学习将图像中的物体位置信息映射到特定的XML标记序列
训练数据中的XML标记序列作为标签(labels)，用于计算交叉熵损失



以目标检测为例，模型学习过程如下：
输入阶段：
图像通过视觉编码器得到特征映射
文本提示"Detect all stadium in the image"被编码
推理阶段：
模型结合视觉特征和文本指令，识别图像中的"stadium"
内部注意力机制关注图像中相关区域的特征
生成阶段：
模型生成文本序列，包含XML标记形式的坐标
例如：<604><352><677><410>\n<411><123><484><179>
这些数字表示检测到的两个体育场的边界框坐标



XML格式坐标表示的核心在于将视觉空间信息与文本序列生成联系起来，通过大规模有监督训练，
模型学会了在合适的情境下生成符合特定格式的XML标记序列。这种方法不需要显式地教模型理解XML的语法，
而是通过统计学习的方式，让模型捕捉到视觉内容、
任务指令和输出格式之间的关联，实现了空间任务到序列生成的转化，使得统一处理多种遥感任务成为可能。


以分割任务为例，完整流程如下：
训练阶段：
原始分割掩码被转换为多边形轮廓
轮廓坐标被量化到1000×1000网格中
量化后的坐标被转换为<poly><x1><y1><x2><y2>...</poly>格式
模型学习生成这种格式的坐标序列
推理阶段：
模型生成类似<poly><465><221><443>...</poly>的坐标序列
系统提取这些坐标并将它们重组为(x,y)对
使用dequantize函数将坐标映射回实际图像尺寸
最终通过polygon_to_mask函数生成像素级掩码

{
  "conversations": [
    {"content": "<image>\nPIX_SEG\nSegment out road in the image."},
    {"content": "<poly><465><221><443><279>...</poly>"}
  ],
  "images": ["path/to/image.png"]
}


{
  "conversations": [
    {"content": "<image>\nPIX_CHG\nFind changes in the two images."},
    {"content": "<poly><342><108><356><187><421><202><499><156><486><89><411><74></poly>"}
  ],
  "images": [
    "path/to/before_image.png", 
    "path/to/after_image.png"
  ],
  "crop": []
}



采用视觉-语言多模态架构，同时处理图像和文本输入
利用因果语言模型范式，以自回归方式生成标记序列
对于分割任务，目标是生成描述多边形的XML格式文本
通过cross-entropy损失函数训练模型预测正确的标记序列
坐标点（如<poly><465><221>...</poly>）被视为标记序列来学习


label和预测的token序列来进行交叉熵损失计算


模型对每个位置预测下一个标记（token）的概率分布
将这个概率分布与实际应该出现的标记（真实标签）进行比较
使用交叉熵公式计算二者之间的差异程度


例如，当模型需要生成坐标序列时，它会逐个标记预测：先预测<poly>，然后预测<465>，再预测<221>等等。
在每一步，交叉熵损失会计算模型预测的概率分布与真实标记之间的差异。
这种方式很巧妙，因为它把分割任务中的坐标点生成问题转化为了一个标准的自回归文本生成问题，
使模型可以用统一的方式处理各种任务，而不需要为每种任务设计专门的网络结构或损失函数。